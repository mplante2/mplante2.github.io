---
title: "Assignment12"
author: "Morgann Plante"
date: "10/19/2020"
output: html_document
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](fa2020_assignment12.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Blackboard.

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


-------

1. Install the package `mlbench` and use the follows to import the data

```{r}
library(tidyverse)
library(caret)
library(rpart)
library(mlbench)
data(PimaIndiansDiabetes)
df <- PimaIndiansDiabetes
```

- Set seed to be 2020. 
- Partition the data into 80% training and 20% testing.  
```{r}
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$diabetes , p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
```

-------

2. Use cross-validation of 30 folds to tune random forest (method='rf').  What is the `mtry` value that produces the greatest accuracy?
```{r}
tuneGrid = expand.grid(mtry = 2:8)
trControl = trainControl(method = "cv",
                         number = 30)
forest_cv <- train(diabetes~., data=df_train, 
                                method = "rf", 
                                trControl = trControl,
                                tuneGrid = tuneGrid)
plot(forest_cv)
print(forest_cv)
```
 
-------

3. Use cross-validation with of 30 folds to tune random forest (method='ranger').  What are the parameters that produce the greatest accuracy?
```{r}
trControl = trainControl(method = "cv",
                         number = 30)
tuneGrid = expand.grid(mtry = 2:8,
                       splitrule = c('gini', 'extratrees'),
                       min.node.size = c(1:8))
ranger_cv <- train(diabetes~., data=df_train, 
                    method = "ranger", 
                    trControl = trControl,
                    tuneGrid = tuneGrid)
plot(ranger_cv)
```

-------

4. Go to https://topepo.github.io/caret/available-models.html and pick a classification model.  Tune the classification model using cross-validation of 30 folds. 
```{r}
library(readxl)
library(tidyverse)
library(xgboost)

X_train = xgb.DMatrix(as.matrix(df_train %>% select(-diabetes)))
y_train = df_train$diabetes

xgb_trcontrol = trainControl(
  method = "cv",
  number = 30,  
  allowParallel = TRUE,
  verboseIter = FALSE,
  returnData = FALSE
)

xgbGrid <- expand.grid(nrounds = c(100,200),
                       max_depth = c(10, 15, 20, 25),
                       colsample_bytree = seq(0.5, 0.9, length.out = 5),
                       eta = 0.1,
                       gamma=0,
                       min_child_weight = 1,
                       subsample = 1
                      )
set.seed(0) 
xgb_model = train(
  X_train, y_train,  
  trControl = xgb_trcontrol,
  tuneGrid = xgbGrid,
  method = "xgbTree"
)
plot(xgb_model)
```

5. Compare the three models in question 2, 3, and 4 to select the final model.  Evaluate the accuracy of the final model on the test data. 
```{r}
results <- resamples(list(forest = forest_cv,
                          ranger = ranger_cv,
                          xbgTree= xgb_model))
bwplot(results)

pred <- predict(forest_cv, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
```

